"""
AIMåŒ»ç–—é—®è¯Šå·¥ä½œæµæ‰¹å¤„ç†ç³»ç»Ÿ
ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†æ•°æ®é›†ä¸­çš„æ‰€æœ‰ç—…ä¾‹æ ·æœ¬
"""

import argparse
import json
import logging
import os
import sys
import time
import threading
import glob
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from typing import Dict, Any, List, Optional

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from workflow import MedicalWorkflow
from config import LLM_CONFIG

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from guidance.loader import GuidanceLoader

class BatchProcessor:
    """æ‰¹å¤„ç†ç®¡ç†å™¨ï¼Œè´Ÿè´£åè°ƒå¤šçº¿ç¨‹æ‰§è¡Œå’ŒçŠ¶æ€ç®¡ç†"""
    
    def __init__(self, num_threads: int = 20):
        self.num_threads = num_threads
        self.lock = threading.Lock()  # çº¿ç¨‹å®‰å…¨é”
        self.processed_count = 0  # å·²å¤„ç†æ ·æœ¬æ•°
        self.success_count = 0    # æˆåŠŸå¤„ç†æ•°
        self.failed_count = 0     # å¤±è´¥å¤„ç†æ•°
        self.skipped_count = 0    # è·³è¿‡çš„æ ·æœ¬æ•°
        self.results = []         # ç»“æœåˆ—è¡¨
        self.failed_samples = []  # å¤±è´¥æ ·æœ¬åˆ—è¡¨
        self.start_time = None    # å¼€å§‹æ—¶é—´
        
    def update_progress(self, success: bool, result: Dict[str, Any] = None, 
                       error: Exception = None, sample_index: int = None):
        """çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°å¤„ç†è¿›åº¦"""
        with self.lock:
            self.processed_count += 1
            if success:
                self.success_count += 1
                if result:
                    self.results.append(result)
            else:
                self.failed_count += 1
                if error and sample_index is not None:
                    self.failed_samples.append({
                        'sample_index': sample_index,
                        'error': str(error),
                        'timestamp': datetime.now().isoformat()
                    })
    
    def update_skipped(self, sample_index: int):
        """çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°è·³è¿‡æ ·æœ¬è®¡æ•°"""
        with self.lock:
            self.skipped_count += 1
            logging.info(f"æ ·æœ¬ {sample_index} å·²å®Œæˆï¼Œè·³è¿‡å¤„ç†")
                    
    def get_progress_stats(self) -> Dict[str, Any]:
        """è·å–å½“å‰è¿›åº¦ç»Ÿè®¡"""
        with self.lock:
            elapsed_time = time.time() - self.start_time if self.start_time else 0
            return {
                'processed': self.processed_count,
                'success': self.success_count,
                'failed': self.failed_count,
                'skipped': self.skipped_count,
                'success_rate': self.success_count / max(self.processed_count, 1),
                'elapsed_time': elapsed_time,
                'samples_per_minute': self.processed_count / max(elapsed_time / 60, 0.01)
            }

def setup_logging(log_dir: str, log_level: str = "INFO") -> None:
    """è®¾ç½®æ—¥å¿—è®°å½•é…ç½®"""
    level = getattr(logging, log_level.upper(), logging.INFO)
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(log_dir, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = os.path.join(log_dir, f"batch_processing_{timestamp}.log")

    # ç§»é™¤æ‰€æœ‰ç°æœ‰çš„å¤„ç†å™¨ï¼Œä»¥é¿å…é‡å¤è®°å½•
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
        
    # é…ç½®æ—¥å¿—è®°å½•
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_filename, encoding='utf-8')
        ]
    )
    

def parse_arguments() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="AIMåŒ»ç–—é—®è¯Šå·¥ä½œæµæ‰¹å¤„ç†ç³»ç»Ÿ",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # æ•°æ®è¾“å…¥é…ç½®
    parser.add_argument(
        '--dataset-path', 
        type=str, 
        default='research/dataset/test_data.json',
        help='æ•°æ®é›†JSONæ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--department_guidance_file', 
        type=str, 
        default='guidance/department_inquiry_guidance.json', 
        help='åŠ¨æ€è¯¢é—®æŒ‡å¯¼åŠ è½½è·¯å¾„'
    )
    parser.add_argument(
        '--comparison_rules_file', 
        type=str, 
        default='guidance/department_comparison_guidance.json', 
        help='åŠ è½½ç§‘å®¤å¯¹æ¯”æŒ‡å¯¼è·¯å¾„'
    )
    # æ•°æ®å’Œè¾“å‡ºé…ç½®
    parser.add_argument(
        '--log-dir', 
        type=str, 
        default='results/results09010-score_driven',
        help='æ—¥å¿—æ–‡ä»¶ä¿å­˜ç›®å½•'
    )
    parser.add_argument(
        '--output-dir', 
        type=str, 
        default='results/batch_results',
        help='æ‰¹å¤„ç†ç»“æœä¿å­˜ç›®å½•'
    )
    parser.add_argument(
        '--batch-log-dir', 
        type=str, 
        default='results/logs',
        help='æ‰¹å¤„ç†è¿è¡Œæ—¶æ—¥å¿—ä¿å­˜ç›®å½•'
    )
    # æ‰§è¡Œå‚æ•°
    parser.add_argument(
        '--num-threads', 
        type=int, 
        default=1,
        help='å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°'
    )
    parser.add_argument(
        '--max-steps', 
        type=int, 
        default=30,
        help='æ¯ä¸ªå·¥ä½œæµçš„æœ€å¤§æ‰§è¡Œæ­¥æ•°'
    )
    parser.add_argument(
        '--start-index', 
        type=int, 
        default=0,
        help='å¼€å§‹å¤„ç†çš„æ ·æœ¬ç´¢å¼•'
    )
    parser.add_argument(
        '--end-index', 
        type=int, 
        default=5000,
        help='ç»“æŸå¤„ç†çš„æ ·æœ¬ç´¢å¼•ï¼ˆä¸åŒ…å«ï¼‰'
    )
    parser.add_argument(
        '--sample-limit', 
        type=int, 
        default=None,
        help='é™åˆ¶å¤„ç†çš„æ ·æœ¬æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰'
    )
    parser.add_argument(
        '--department_filter', 
        type=str, 
        default=None,
        help='ç­›é€‰ç‰¹å®šä¸€çº§ç§‘å®¤çš„ç—…ä¾‹ (ä¾‹å¦‚: å†…ç§‘, å¤–ç§‘, å„¿ç§‘ç­‰)'
    )
    parser.add_argument(
        '--use_inquiry_guidance', 
        action='store_true', 
        default=True,
        help='æ˜¯å¦ä½¿ç”¨ç§‘å®¤ç‰¹å®šçš„è¯¢é—®æŒ‡å¯¼ (æ— è®ºæ˜¯å›ºå®šæŒ‡å¯¼è¿˜æ˜¯è¯¢é—®æŒ‡å¯¼ï¼Œé»˜è®¤: True)'
    )
    parser.add_argument(
        '--use_dynamic_guidance', 
        action='store_true', 
        default=True,
        help='æ˜¯å¦ä½¿ç”¨åŠ¨æ€è¯¢é—®ç§‘å®¤æŒ‡å¯¼ (é»˜è®¤: True)'
    )
    parser.add_argument(
        '--use_department_comparison', 
        action='store_true', 
        default=True,
        help='æ˜¯å¦ä½¿ç”¨ç§‘å®¤å¯¹æ¯”é‰´åˆ«åŠŸèƒ½ (é»˜è®¤: True)'
    )

    # æ¨¡å‹é…ç½®
    available_models = list(LLM_CONFIG.keys())
    parser.add_argument(
        '--model-type', 
        type=str, 
        choices=available_models,
        default='deepseek',
        help=f'ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹ç±»å‹ï¼Œå¯é€‰: {", ".join(available_models)}'
    )
    parser.add_argument(
        '--list-models', 
        action='store_true',
        help='æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®å¹¶é€€å‡º'
    )
    parser.add_argument(
        '--model-config', 
        type=str, 
        default=None,
        help='æ¨¡å‹é…ç½®JSONå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤é…ç½®ï¼‰'
    )
    parser.add_argument(
        '--controller-mode',
        type=str,
        choices=['normal', 'sequence', 'score_driven'],
        default='score_driven',
        help='ä»»åŠ¡æ§åˆ¶å™¨æ¨¡å¼ï¼šnormalä¸ºæ™ºèƒ½æ¨¡å¼ï¼ˆéœ€è¦LLMæ¨ç†ï¼‰ï¼Œsequenceä¸ºé¡ºåºæ¨¡å¼ï¼ˆç›´æ¥é€‰æ‹©ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼‰ï¼Œscore_drivenä¸ºåˆ†æ•°é©±åŠ¨æ¨¡å¼ï¼ˆé€‰æ‹©å½“å‰ä»»åŠ¡ç»„ä¸­åˆ†æ•°æœ€ä½çš„ä»»åŠ¡ï¼‰'
    )
    
    
    # è°ƒè¯•å’Œæ—¥å¿—
    parser.add_argument(
        '--log-level', 
        type=str, 
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help='æ—¥å¿—è®°å½•çº§åˆ«'
    )
    parser.add_argument(
        '--progress-interval', 
        type=int, 
        default=10,
        help='è¿›åº¦æŠ¥å‘Šé—´éš”ï¼ˆç§’ï¼‰'
    )
    parser.add_argument(
        '--dry-run', 
        action='store_true',
        help='è¯•è¿è¡Œæ¨¡å¼ï¼ŒåªéªŒè¯é…ç½®ä¸æ‰§è¡Œå¤„ç†'
    )
    
    return parser.parse_args()

def is_case_completed(log_dir: str, case_index: int) -> bool:
    """
    æ£€æŸ¥æŒ‡å®šcaseæ˜¯å¦å·²ç»å®Œæˆå·¥ä½œæµ
    å¦‚æœå­˜åœ¨ä¸å®Œæ•´çš„æ–‡ä»¶åˆ™åˆ é™¤ï¼Œç¡®ä¿æ¯ä¸ªcaseåœ¨ç›®å½•ä¸­åªå‡ºç°ä¸€æ¬¡
    
    Args:
        log_dir: æ—¥å¿—ç›®å½•
        case_index: caseåºå·
        
    Returns:
        bool: å¦‚æœcaseå·²å®Œæˆè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    # æ„å»ºæ–‡ä»¶è·¯å¾„æ¨¡å¼ï¼šworkflow_*_case_{case_index:04d}.jsonl
    pattern = os.path.join(log_dir, f"workflow_*_case_{case_index:04d}.jsonl")
    matching_files = glob.glob(pattern)
    
    if not matching_files:
        return False
    
    # åº”è¯¥åªæœ‰ä¸€ä¸ªåŒ¹é…çš„æ–‡ä»¶
    if len(matching_files) > 1:
        logging.warning(f"å‘ç°å¤šä¸ªåŒ¹é…æ–‡ä»¶ case {case_index}: {matching_files}")
    
    # æ£€æŸ¥æ¯ä¸ªåŒ¹é…çš„æ–‡ä»¶
    for log_file in matching_files:
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                # è¯»å–æœ€åä¸€è¡Œ
                lines = f.readlines()
                if not lines:
                    # æ–‡ä»¶ä¸ºç©ºï¼Œåˆ é™¤
                    try:
                        os.remove(log_file)
                        logging.info(f"åˆ é™¤ç©ºæ–‡ä»¶: {log_file}")
                    except (OSError, FileNotFoundError, PermissionError) as e:
                        # æ–‡ä»¶åˆ é™¤å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œè®°å½•è­¦å‘Šå³å¯
                        logging.warning(f"æ— æ³•åˆ é™¤ç©ºæ–‡ä»¶ {log_file}: {e}")
                    continue
                
                last_line = lines[-1].strip()
                if not last_line:
                    # æœ€åä¸€è¡Œä¸ºç©ºï¼Œåˆ é™¤
                    try:
                        os.remove(log_file)
                        logging.info(f"åˆ é™¤æœ€åä¸€è¡Œä¸ºç©ºçš„æ–‡ä»¶: {log_file}")
                    except (OSError, FileNotFoundError, PermissionError) as e:
                        # æ–‡ä»¶åˆ é™¤å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œè®°å½•è­¦å‘Šå³å¯
                        logging.warning(f"æ— æ³•åˆ é™¤æœ€åä¸€è¡Œä¸ºç©ºçš„æ–‡ä»¶ {log_file}: {e}")
                    continue
                
                # è§£ææœ€åä¸€è¡Œçš„JSON
                try:
                    last_entry = json.loads(last_line)
                    if last_entry.get("event_type") == "workflow_complete":
                        # æ‰¾åˆ°å®Œæ•´çš„æ–‡ä»¶
                        logging.info(f"å‘ç°å·²å®Œæˆçš„case {case_index}: {log_file}")
                        return True
                    else:
                        # æ–‡ä»¶ä¸å®Œæ•´ï¼Œåˆ é™¤
                        try:
                            os.remove(log_file)
                            logging.info(f"åˆ é™¤ä¸å®Œæ•´çš„æ–‡ä»¶: {log_file}")
                        except (OSError, FileNotFoundError, PermissionError) as e:
                            # æ–‡ä»¶åˆ é™¤å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œè®°å½•è­¦å‘Šå³å¯
                            logging.warning(f"æ— æ³•åˆ é™¤ä¸å®Œæ•´çš„æ–‡ä»¶ {log_file}: {e}")
                        continue
                        
                except json.JSONDecodeError:
                    # JSONè§£æå¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶
                    try:
                        os.remove(log_file)
                        logging.info(f"åˆ é™¤JSONæ ¼å¼é”™è¯¯çš„æ–‡ä»¶: {log_file}")
                    except (OSError, FileNotFoundError, PermissionError) as e:
                        # æ–‡ä»¶åˆ é™¤å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œè®°å½•è­¦å‘Šå³å¯
                        logging.warning(f"æ— æ³•åˆ é™¤JSONæ ¼å¼é”™è¯¯çš„æ–‡ä»¶ {log_file}: {e}")
                    continue
                    
        except Exception as e:
            logging.warning(f"æ£€æŸ¥æ–‡ä»¶ {log_file} æ—¶å‡ºé”™: {e}")
            # å‡ºç°å¼‚å¸¸ä¹Ÿåˆ é™¤æ–‡ä»¶ï¼Œé¿å…åç»­é—®é¢˜
            try:
                os.remove(log_file)
                logging.info(f"åˆ é™¤å¼‚å¸¸æ–‡ä»¶: {log_file}")
            except (OSError, FileNotFoundError, PermissionError) as delete_error:
                # ä¿®å¤1ï¼šæ˜ç¡®æŒ‡å®šè¦æ•è·çš„å¼‚å¸¸ç±»å‹
                # ä¿®å¤2ï¼šæ·»åŠ è§£é‡Šæ€§æ³¨é‡Š
                # æ–‡ä»¶åˆ é™¤å¤±è´¥ä¸æ˜¯è‡´å‘½é”™è¯¯ï¼Œå¯èƒ½æ˜¯æƒé™é—®é¢˜æˆ–æ–‡ä»¶å·²è¢«å…¶ä»–è¿›ç¨‹å ç”¨
                # è®°å½•è­¦å‘Šåç»§ç»­å¤„ç†ï¼Œä¸ä¸­æ–­æ•´ä¸ªæ£€æŸ¥æµç¨‹
                logging.warning(f"æ— æ³•åˆ é™¤å¼‚å¸¸æ–‡ä»¶ {log_file}: {delete_error}")
            except Exception as unexpected_error:
                # å¤„ç†å…¶ä»–æ„å¤–çš„åˆ é™¤å¼‚å¸¸ï¼ˆæ¯”å¦‚ç£ç›˜æ»¡ç­‰ï¼‰
                # è¿™äº›é”™è¯¯ä¹Ÿä¸åº”è¯¥ä¸­æ–­æ£€æŸ¥æµç¨‹
                logging.error(f"åˆ é™¤æ–‡ä»¶æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ {log_file}: {unexpected_error}")
            continue
    
    # æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶éƒ½è¢«åˆ é™¤æˆ–æ²¡æœ‰å®Œæ•´çš„æ–‡ä»¶
    return False

def load_dataset(dataset_path: str, start_index: int = 0, 
                end_index: Optional[int] = None, 
                sample_limit: Optional[int] = None) -> List[Dict[str, Any]]:
    """åŠ è½½å’ŒéªŒè¯æ•°æ®é›†"""
    logging.info(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {dataset_path}")
    
    if not os.path.exists(dataset_path):
        raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {dataset_path}")
    
    try:
        with open(dataset_path, 'r', encoding='utf-8') as f:
            full_dataset = json.load(f)
    except json.JSONDecodeError as e:
        raise ValueError(f"æ•°æ®é›†JSONæ ¼å¼é”™è¯¯: {e}")
    except Exception as e:
        raise Exception(f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
    
    if not isinstance(full_dataset, list):
        raise ValueError("æ•°æ®é›†åº”è¯¥æ˜¯åŒ…å«ç—…ä¾‹çš„JSONæ•°ç»„")
    
    total_samples = len(full_dataset)
    logging.info(f"æ•°æ®é›†æ€»æ ·æœ¬æ•°: {total_samples}")
    
    # ç¡®å®šå¤„ç†èŒƒå›´
    if end_index is None:
        end_index = total_samples
    
    end_index = min(end_index, total_samples)
    start_index = max(0, start_index)
    
    if sample_limit:
        end_index = min(start_index + sample_limit, end_index)
    
    if start_index >= end_index:
        raise ValueError(f"æ— æ•ˆçš„ç´¢å¼•èŒƒå›´: start_index={start_index}, end_index={end_index}")
    
    # æå–æŒ‡å®šèŒƒå›´çš„æ•°æ®
    dataset = full_dataset[start_index:end_index]
    
    logging.info(f"å°†å¤„ç†æ ·æœ¬èŒƒå›´: [{start_index}, {end_index}), å…± {len(dataset)} ä¸ªæ ·æœ¬")
    
    # éªŒè¯æ•°æ®æ ¼å¼
    for i, sample in enumerate(dataset[:5]):  # åªéªŒè¯å‰5ä¸ªæ ·æœ¬
        if not isinstance(sample, dict):
            raise ValueError(f"æ ·æœ¬ {start_index + i} æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºå­—å…¸ç±»å‹")
        
        required_keys = ['ç—…æ¡ˆä»‹ç»']
        for key in required_keys:
            if key not in sample:
                logging.warning(f"æ ·æœ¬ {start_index + i} ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}")
    
    return dataset


def process_single_sample(sample_data: Dict[str, Any], sample_index: int, 
                         args: argparse.Namespace, 
                         processor: BatchProcessor) -> Dict[str, Any]:
    """å¤„ç†å•ä¸ªæ ·æœ¬çš„å·¥ä½œå‡½æ•°"""
    thread_id = threading.current_thread().ident
    start_time = time.time()
    
    
    try:
        # ä½¿ç”¨ LLM_CONFIG ä½œä¸ºåŸºç¡€é…ç½®
        # BaseAgent ä¼šæ ¹æ® model_type è‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„æ¨¡å‹é…ç½®
        llm_config = LLM_CONFIG.copy()
        
        # å¦‚æœç”¨æˆ·æä¾›äº†é¢å¤–çš„æ¨¡å‹é…ç½®ï¼Œåˆ™åˆå¹¶åˆ°å¯¹åº”çš„æ¨¡å‹é…ç½®ä¸­
        if args.model_config:
            try:
                user_config = json.loads(args.model_config)
                # æ›´æ–°é€‰å®šæ¨¡å‹çš„é…ç½®
                if args.model_type in llm_config:
                    llm_config[args.model_type]["params"].update(user_config.get("params", {}))
                else:
                    logging.warning(f"æ ·æœ¬ {sample_index}: æ¨¡å‹ç±»å‹ {args.model_type} ä¸å­˜åœ¨ï¼Œå¿½ç•¥ç”¨æˆ·é…ç½®")
            except json.JSONDecodeError:
                logging.warning(f"æ ·æœ¬ {sample_index}: æ¨¡å‹é…ç½®JSONæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        
        #æ˜¯å¦ä½¿ç”¨å›ºå®šç§‘å®¤æ¨¡å¼
        department_guidance = ""

        # åˆå§‹åŒ– GuidanceLoader
        loader = GuidanceLoader(
            department_guidance = department_guidance,
            use_dynamic_guidance=args.use_dynamic_guidance,
            use_department_comparison=args.use_department_comparison,
            department_guidance_file=args.department_guidance_file,
            comparison_rules_file=args.comparison_rules_file
        )

        if args.use_inquiry_guidance:
            if args.department_filter:
                # å›ºå®šç§‘å®¤æ¨¡å¼
                department_guidance = loader.load_inquiry_guidance(args.department_filter)
                
                # å°†åŠ è½½å¥½çš„æŒ‡å¯¼åŒæ­¥å› loader å®ä¾‹
                loader.department_guidance = department_guidance

                if department_guidance:
                    print(f"âœ… å·²åŠ è½½ '{args.department_filter}' ç§‘å®¤çš„å›ºå®šè¯¢é—®æŒ‡å¯¼")
                else:
                    print(f"âš ï¸ æœªèƒ½åŠ è½½ '{args.department_filter}' ç§‘å®¤çš„è¯¢é—®æŒ‡å¯¼ï¼Œå°†ä½¿ç”¨é»˜è®¤è¯¢é—®æ¨¡å¼")
            else:
                # åŠ¨æ€æŒ‡å¯¼æ¨¡å¼
                if args.max_steps > 1 and args.use_dynamic_guidance:
                    print(f"ğŸ”„ å·²å¯ç”¨åŠ¨æ€ç§‘å®¤è¯¢é—®æŒ‡å¯¼æ¨¡å¼")
                else:
                    print(f"âš ï¸ å•æ­¥é—®è¯Šä¸éœ€è¦åŠ¨æ€æŒ‡å¯¼ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å¼")

        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = MedicalWorkflow(
            case_data=sample_data,
            model_type=args.model_type,
            llm_config=llm_config,
            max_steps=args.max_steps,
            log_dir=args.log_dir,
            case_index=sample_index,
            controller_mode=args.controller_mode,
            guidance_loader=loader, #å°† loader ä¼ é€’ç»™ MedicalWorkflow
            department_guidance=department_guidance
        )
        
        # æ‰§è¡Œå·¥ä½œæµ
        logging.debug(f"çº¿ç¨‹ {thread_id}: å¼€å§‹å¤„ç†æ ·æœ¬ {sample_index}")
        log_file_path = workflow.run()
        
        execution_time = time.time() - start_time
        
        # è·å–æ‰§è¡Œç»“æœ
        workflow_status = workflow.get_current_status()
        medical_summary = workflow.get_medical_summary()
        
        # æ„å»ºç»“æœ
        result = {
            'sample_index': sample_index,
            'thread_id': thread_id,
            'execution_time': execution_time,
            'log_file_path': log_file_path,
            'workflow_status': workflow_status,
            'medical_summary': medical_summary,
            'processed_at': datetime.now().isoformat()
        }
        
        
        # æ›´æ–°è¿›åº¦
        processor.update_progress(success=True, result=result)
        
        logging.info(f"æ ·æœ¬ {sample_index} å¤„ç†å®Œæˆ (è€—æ—¶: {execution_time:.2f}s, "
                    f"æ­¥æ•°: {workflow_status['current_step']}, "
                    f"æˆåŠŸ: {workflow_status['workflow_success']})")
        
        return result
        
    except Exception as e:
        execution_time = time.time() - start_time
        error_msg = f"æ ·æœ¬ {sample_index} å¤„ç†å¤±è´¥: {str(e)}"
        
        
        logging.error(error_msg)
        processor.update_progress(success=False, error=e, sample_index=sample_index)
        
        # è¿”å›é”™è¯¯ç»“æœ
        return {
            'sample_index': sample_index,
            'thread_id': thread_id,
            'execution_time': execution_time,
            'error': str(e),
            'processed_at': datetime.now().isoformat(),
            'success': False
        }

def print_progress_report(processor: BatchProcessor, total_samples: int):
    """æ‰“å°è¿›åº¦æŠ¥å‘Š"""
    stats = processor.get_progress_stats()
    
    print(f"\n=== å¤„ç†è¿›åº¦æŠ¥å‘Š ===")
    print(f"å·²å¤„ç†: {stats['processed']}/{total_samples} ({stats['processed']/total_samples:.1%})")
    print(f"æˆåŠŸ: {stats['success']} | å¤±è´¥: {stats['failed']} | è·³è¿‡: {stats['skipped']} | æˆåŠŸç‡: {stats['success_rate']:.1%}")
    print(f"è€—æ—¶: {stats['elapsed_time']:.1f}s | å¤„ç†é€Ÿåº¦: {stats['samples_per_minute']:.1f} æ ·æœ¬/åˆ†é’Ÿ")
    remaining_samples = total_samples - stats['processed'] - stats['skipped']
    print(f"é¢„è®¡å‰©ä½™æ—¶é—´: {remaining_samples / max(stats['samples_per_minute'] / 60, 0.01):.1f}s")
    print("=" * 50)

def run_workflow_batch(dataset: List[Dict[str, Any]], args: argparse.Namespace) -> Dict[str, Any]:
    """æ‰§è¡Œæ‰¹é‡å·¥ä½œæµå¤„ç†"""
    total_samples = len(dataset)
    logging.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {total_samples} ä¸ªæ ·æœ¬ï¼Œä½¿ç”¨ {args.num_threads} ä¸ªçº¿ç¨‹")
    
    # åˆ›å»ºæ‰¹å¤„ç†ç®¡ç†å™¨
    processor = BatchProcessor(num_threads=args.num_threads)
    processor.start_time = time.time()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    os.makedirs(args.log_dir, exist_ok=True)
    
    # å¯åŠ¨è¿›åº¦ç›‘æ§çº¿ç¨‹
    def progress_monitor():
        while processor.processed_count + processor.skipped_count < total_samples:
            time.sleep(args.progress_interval)
            if processor.processed_count + processor.skipped_count < total_samples:
                print_progress_report(processor, total_samples)
    
    progress_thread = threading.Thread(target=progress_monitor, daemon=True)
    progress_thread.start()
    
    try:
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œæ‰¹å¤„ç†
        with ThreadPoolExecutor(max_workers=args.num_threads) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {}
            for i, sample_data in enumerate(dataset):
                sample_index = args.start_index + i
                
                # æ£€æŸ¥caseæ˜¯å¦å·²ç»å®Œæˆ
                if is_case_completed(args.log_dir, sample_index):
                    processor.update_skipped(sample_index)
                    continue
                
                future = executor.submit(
                    process_single_sample, 
                    sample_data, 
                    sample_index, 
                    args, 
                    processor
                )
                future_to_index[future] = sample_index
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in as_completed(future_to_index):
                sample_index = future_to_index[future]
                try:
                    _ = future.result()  # ç»“æœå·²ç»åœ¨process_single_sampleä¸­å¤„ç†
                except Exception as e:
                    logging.error(f"çº¿ç¨‹æ‰§è¡Œå¼‚å¸¸ (æ ·æœ¬ {sample_index}): {e}")
    
    except KeyboardInterrupt:
        logging.warning("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢å¤„ç†...")
        executor.shutdown(wait=False)
        raise
    
    # æœ€ç»ˆè¿›åº¦æŠ¥å‘Š
    total_time = time.time() - processor.start_time
    stats = processor.get_progress_stats()
    
    print_progress_report(processor, total_samples)
    
    # æ„å»ºæœ€ç»ˆç»“æœæ‘˜è¦
    summary = {
        'total_samples': total_samples,
        'processed_samples': processor.processed_count,
        'successful_samples': processor.success_count,
        'failed_samples': processor.failed_count,
        'skipped_samples': processor.skipped_count,
        'success_rate': stats['success_rate'],
        'total_execution_time': total_time,
        'average_time_per_sample': total_time / max(processor.processed_count, 1),
        'samples_per_minute': stats['samples_per_minute'],
        'failed_sample_details': processor.failed_samples,
        'processing_config': {
            'num_threads': args.num_threads,
            'model_type': args.model_type,
            'max_steps': args.max_steps,
            'dataset_range': f"[{args.start_index}, {args.start_index + len(dataset)})"
        }
    }
    
    return {
        'summary': summary,
        'results': processor.results
    }

def generate_summary_report(batch_results: Dict[str, Any], 
                          output_path: str) -> None:
    """ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡Œæ‘˜è¦æŠ¥å‘Š"""
    summary = batch_results['summary']
    results = batch_results['results']
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ç”ŸæˆJSONæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š
    detailed_report = {
        'batch_execution_summary': summary,
        'sample_results': results,
        'generated_at': datetime.now().isoformat(),
        'report_version': '1.0'
    }
    
    report_file = os.path.join(output_path, f'batch_report_{timestamp}.json')
    
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_report, f, ensure_ascii=False, indent=2)
        
        logging.info(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # ç”Ÿæˆäººç±»å¯è¯»çš„æ‘˜è¦
        summary_file = os.path.join(output_path, f'batch_summary_{timestamp}.txt')
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("AIMåŒ»ç–—é—®è¯Šå·¥ä½œæµæ‰¹å¤„ç†æ‰§è¡Œæ‘˜è¦\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ€»æ ·æœ¬æ•°: {summary['total_samples']}\n")
            f.write(f"å¤„ç†æ ·æœ¬æ•°: {summary['processed_samples']}\n")
            f.write(f"æˆåŠŸæ ·æœ¬æ•°: {summary['successful_samples']}\n")
            f.write(f"å¤±è´¥æ ·æœ¬æ•°: {summary['failed_samples']}\n")
            f.write(f"è·³è¿‡æ ·æœ¬æ•°: {summary['skipped_samples']}\n")
            f.write(f"æˆåŠŸç‡: {summary['success_rate']:.2%}\n")
            f.write(f"æ€»æ‰§è¡Œæ—¶é—´: {summary['total_execution_time']:.2f} ç§’\n")
            f.write(f"å¹³å‡å¤„ç†æ—¶é—´: {summary['average_time_per_sample']:.2f} ç§’/æ ·æœ¬\n")
            f.write(f"å¤„ç†é€Ÿåº¦: {summary['samples_per_minute']:.2f} æ ·æœ¬/åˆ†é’Ÿ\n\n")
            
            f.write("å¤„ç†é…ç½®:\n")
            for key, value in summary['processing_config'].items():
                f.write(f"  {key}: {value}\n")
            
            if summary['failed_samples'] > 0:
                f.write(f"\nå¤±è´¥æ ·æœ¬è¯¦æƒ…:\n")
                for failed in summary['failed_sample_details']:
                    f.write(f"  æ ·æœ¬ {failed['sample_index']}: {failed['error']}\n")
        
        logging.info(f"æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜: {summary_file}")
        
    except Exception as e:
        logging.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å…¥å£å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_arguments()

    # # ç¤ºä¾‹1ï¼šè°ƒè¯•å†…ç§‘ï¼Œå¹¶åªå¤„ç†2ä¸ªæ ·æœ¬
    # args.department_filter = 'å†…ç§‘'
    # args.sample_limit = 2
    
    # å¤„ç† --list-models å‚æ•°
    if args.list_models:
        print("å¯ç”¨çš„è¯­è¨€æ¨¡å‹é…ç½®:")
        print("=" * 50)
        for model_name, config in LLM_CONFIG.items():
            print(f"æ¨¡å‹åç§°: {model_name}")
            print(f"  ç±»åˆ«: {config['class']}")
            print(f"  æ¨¡å‹ID: {config['params']['id']}")
            print(f"  APIç«¯ç‚¹: {config['params']['base_url']}")
            print("-" * 30)
        return 0
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.batch_log_dir, args.log_level)
    
    logging.info("=" * 60)
    logging.info("AIMåŒ»ç–—é—®è¯Šå·¥ä½œæµæ‰¹å¤„ç†ç³»ç»Ÿå¯åŠ¨")
    logging.info("=" * 60)
    
    try:
        # éªŒè¯å‚æ•°
        if args.num_threads <= 0:
            raise ValueError("çº¿ç¨‹æ•°å¿…é¡»å¤§äº0")
        
        if args.max_steps <= 0:
            raise ValueError("æœ€å¤§æ­¥æ•°å¿…é¡»å¤§äº0")
        
        # éªŒè¯æ¨¡å‹ç±»å‹
        if args.model_type not in LLM_CONFIG:
            available_models = ', '.join(LLM_CONFIG.keys())
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {args.model_type}ï¼Œå¯ç”¨æ¨¡å‹: {available_models}")
        
        logging.info(f"ä½¿ç”¨æ¨¡å‹: {args.model_type} ({LLM_CONFIG[args.model_type]['class']})")
        
        # è¯•è¿è¡Œæ¨¡å¼
        if args.dry_run:
            logging.info("è¯•è¿è¡Œæ¨¡å¼ï¼šéªŒè¯é…ç½®...")
            dataset = load_dataset(
                args.dataset_path, 
                args.start_index, 
                args.end_index, 
                min(args.sample_limit or 5, 5)  # è¯•è¿è¡ŒåªéªŒè¯å‰5ä¸ªæ ·æœ¬
            )
            logging.info(f"é…ç½®éªŒè¯æˆåŠŸï¼Œå°†å¤„ç† {len(dataset)} ä¸ªæ ·æœ¬")
            return 0
        
        # åŠ è½½æ•°æ®é›†
        dataset = load_dataset(
            args.dataset_path, 
            args.start_index, 
            args.end_index, 
            args.sample_limit
        )
        
        # å¦‚æœæŒ‡å®šäº†ç§‘å®¤ç­›é€‰ï¼Œå…ˆç­›é€‰å‡ºæŒ‡å®šç§‘å®¤çš„ç—…ä¾‹
        if args.department_filter:
            filtered_dataset = []
            for case in dataset:
                if case.get('ä¸€çº§ç§‘å®¤', '') == args.department_filter:
                    filtered_dataset.append(case)
            dataset = filtered_dataset
            print(f"ç­›é€‰ '{args.department_filter}' ç§‘å®¤ç—…ä¾‹: {len(dataset)} ä¸ª")

            #åœ¨å›ºå®šç§‘å®¤æ¨¡å¼ä¸‹
            args.use_dynamic_guidance = False
            logging.info("å›ºå®šç§‘å®¤æ¨¡å¼å·²æ¿€æ´»ï¼ŒåŠ¨æ€æŒ‡å¯¼å·²ç¦ç”¨ã€‚")

        total_cases = len(dataset)
        if total_cases == 0:
            logging.warning("æ²¡æœ‰æ ·æœ¬éœ€è¦å¤„ç†")
            return 0
        
        # æ‰“å°åˆå§‹åŒ–ä¿¡æ¯
        print(f"æ€»å…±æœ‰ {total_cases} ä¸ªæ‚£è€…ç—…ä¾‹")
        if args.department_filter:
            print(f"ç­›é€‰ç§‘å®¤: {args.department_filter}")
        print(f"æ€»å…±éœ€è¦å¤„ç† {total_cases} ä¸ªæ‚£è€…ç—…ä¾‹")
        print(f"å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°: {args.num_threads}")
        print(f"ç»“æœå°†ä¿å­˜è‡³ {args.output_dir} ç›®å½•")
        if args.use_inquiry_guidance:
            if args.department_filter:
                print(f"ğŸ“‹ å·²å¯ç”¨ '{args.department_filter}' ç§‘å®¤çš„å›ºå®šè¯¢é—®æŒ‡å¯¼")
            elif args.max_steps > 1:
                print(f"ğŸ“‹ å·²å¯ç”¨åŠ¨æ€ç§‘å®¤è¯¢é—®æŒ‡å¯¼æ¨¡å¼")
            else:
                print(f"ğŸ“‹ ä½¿ç”¨é»˜è®¤è¯¢é—®æ¨¡å¼")
        else:
            print(f"ğŸ“‹ ä½¿ç”¨é»˜è®¤è¯¢é—®æ¨¡å¼")
        
        if args.use_department_comparison:
            print(f"ğŸ”„ å·²å¯ç”¨ç§‘å®¤å¯¹æ¯”é‰´åˆ«åŠŸèƒ½")
        else:
            print(f"ğŸ”„ æœªå¯ç”¨ç§‘å®¤å¯¹æ¯”é‰´åˆ«åŠŸèƒ½")
        print("å¼€å§‹å¹¶è¡Œå¤„ç†...\n")
        
        # æ‰§è¡Œæ‰¹å¤„ç†
        logging.info("å¼€å§‹æ‰¹é‡å¤„ç†...")
        batch_results = run_workflow_batch(dataset, args)
        
        # ç”ŸæˆæŠ¥å‘Š
        generate_summary_report(batch_results, args.output_dir)
        
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        summary = batch_results['summary']
        logging.info("=" * 60)
        logging.info("æ‰¹å¤„ç†æ‰§è¡Œå®Œæˆ!")
        logging.info(f"æˆåŠŸç‡: {summary['success_rate']:.2%} ({summary['successful_samples']}/{summary['total_samples']})")
        logging.info(f"æ€»è€—æ—¶: {summary['total_execution_time']:.2f} ç§’")
        logging.info(f"å¤„ç†é€Ÿåº¦: {summary['samples_per_minute']:.2f} æ ·æœ¬/åˆ†é’Ÿ")
        logging.info("=" * 60)
        
        # return 0 if summary['success_rate'] > 0.8 else 1
        return 0

    except KeyboardInterrupt:
        logging.warning("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        logging.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)